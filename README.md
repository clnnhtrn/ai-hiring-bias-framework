# AI Hiring Bias Mitigation Framework

This project implements a machine learning framework to detect and mitigate gender and racial bias in AI-driven hiring systems using resume and job description data.

It applies:
- Preprocessing techniques (intersectional group encoding and reweighting)
- In-processing via fairness-aware model training
- Evaluation across intersectional groups
- Visualisation of fairness metrics like Selection Rate, Accuracy, and Statistical Disparity

---

## ğŸ“Œ Features

- Generates intersectional group labels (e.g., Female-Asian)
- TF-IDF vectorisation of resumes and job descriptions
- Three model variations:
  - **Model A** â€“ Resume + Job Description
  - **Model B** â€“ Model A + Gender + Ethnicity
  - **Model C** â€“ Model A + Intersectional Groups + Sample Reweighting
- Fairness evaluations per group
- Visualisations of model performance and fairness outcomes

---

## âš™ï¸ Requirements

- Python 3.8 or higher
- All required libraries are listed in `requirements.txt`

---

## ğŸš€ Setup Instructions

### Step 1: Clone the Repository

```bash
git clone https://github.com/clnnhtrn/ai-hiring-bias-framework.git
cd ai-hiring-bias-framework
```

### Step 2 (Optional but Recommended): Create a Virtual Environment

```bash
python -m venv venv
# Activate on Windows
venv\Scripts\activate

# Activate on Mac/Linux
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

This installs the following Python packages:

- `pandas`
- `numpy`
- `matplotlib`
- `scikit-learn`
- `scipy`

---

## ğŸ—‚ï¸ Prepare Your Dataset

The dataset used in this framework is the Recruitment Dataset available on Kaggle (https://www.kaggle.com/datasets/surendra365/recruitement-dataset/data)

If you are using your own dataset, your dataset file must be named:

```
job_applicant_dataset.csv
```

It must be placed in the **root directory** of the project (same folder as the Python script).

### Required columns:
- `Resume` â€“ text field
- `Job Description` â€“ text field
- `Gender` â€“ e.g., Male, Female
- `Ethnicity` â€“ e.g., Asian, White, Black
- `Best Match` â€“ binary label (1 = selected, 0 = not selected)

---

## â–¶ï¸ Run the Framework

In the terminal, from the root project folder:

```bash
python main.py
```

---

## ğŸ“¤ Output Files

After running the framework, the following files will be generated automatically:

| File | Description |
|------|-------------|
| `processed_dataset.csv` | Fully processed dataset containing original data, TF-IDF features, and one-hot encoded intersectional groups |
| `framework_output_log.txt` | Text log with model metrics, fairness evaluation results, and comparison summaries |
| Matplotlib plots (displayed) | Visual comparisons for selection rate, accuracy, and disparity across groups and models |

---

## ğŸ§¾ Project Structure

```
ğŸ“ ai-hiring-bias-framework/
â”œâ”€â”€ job_applicant_dataset.csv         # <-- Kaggle dataset
â”œâ”€â”€ main.py                           # Main Python script 
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                        # Full usage guide (this file)
â”œâ”€â”€ .gitignore                       # Ignored files (e.g., venv, logs)
â”œâ”€â”€ processed_dataset.csv            # Generated processed dataset
â”œâ”€â”€ framework_output_log.txt        # Generated model/fairness evaluation log
```

---

## ğŸªª License

This project is licensed under the [MIT License](LICENSE).  
You are free to use, modify, and share it â€” with proper attribution.


---

## ğŸ™‹ Need Help?

If you have any issues setting up or running the code, feel free to:

- [Open an issue on GitHub](https://github.com/clnnhtrn/ai-hiring-bias-framework/issues)

---
